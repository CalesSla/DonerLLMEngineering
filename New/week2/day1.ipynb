{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import google.generativeai\n",
    "import anthropic\n",
    "from IPython.display import Markdown, display, update_display\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "claude = anthropic.Anthropic()\n",
    "\n",
    "google.generativeai.configure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the data scientist break up with their smartphone? Because they couldn't find a good connection!\n"
     ]
    }
   ],
   "source": [
    "system_message = \"You are an assistant that is great at telling jokes.\"\n",
    "user_prompt = \"tell a light-hearted joke for an audience of Data Scientists\"\n",
    "\n",
    "prompts = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "]\n",
    "\n",
    "completion = openai.chat.completions.create(model='gpt-3.5-turbo', messages=prompts)\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the data scientist break up with the statistician?\n",
      "\n",
      "Because she found him too mean!\n"
     ]
    }
   ],
   "source": [
    "completion = openai.chat.completions.create(\n",
    "    model='gpt-4o-mini',\n",
    "    messages=prompts,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the data scientist bring a ladder to work?\n",
      "\n",
      "Because they heard the project was on another level!\n"
     ]
    }
   ],
   "source": [
    "completion = openai.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=prompts,\n",
    "    temperature=0.4\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why do data scientists prefer cats over dogs?\n",
      "\n",
      "Because cats have better feature selection ‚Äì they only come when they want something! \n",
      "\n",
      "Plus, dogs are always overfitting to their training data (treats), while cats maintain better generalization across different households. üê±üìä\n"
     ]
    }
   ],
   "source": [
    "message = claude.messages.create(\n",
    "    model='claude-sonnet-4-20250514',\n",
    "    max_tokens=200,\n",
    "    temperature=0.7,\n",
    "    system=system_message,\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': user_prompt}\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why do data scientists prefer nature hikes?\n",
      "\n",
      "Because they love a good random forest, but they're always worried about overfitting their backpack! üéíüìä\n",
      "\n",
      "*Bonus*: And they're the only people who get genuinely excited when they encounter outliers on the trail!"
     ]
    }
   ],
   "source": [
    "result = claude.messages.stream(\n",
    "    model='claude-sonnet-4-20250514',\n",
    "    max_tokens=200,\n",
    "    temperature=0.7,\n",
    "    system=system_message,\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': user_prompt}\n",
    "    ],\n",
    ")\n",
    "\n",
    "with result as stream:\n",
    "    for text in stream.text_stream:\n",
    "        print(text, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Determining whether a large language model (LLM) is suitable for a business problem involves evaluating several factors related to the nature of the problem and the capabilities of LLMs. Here are some key considerations:\n",
       "\n",
       "1. **Nature of the Task:**\n",
       "   - **Text-Based:** LLMs are particularly suitable for tasks that involve understanding, generating, or manipulating text. If your problem involves textual data, such as documentation, emails, customer inquiries, or reports, an LLM might be appropriate.\n",
       "   - **Complex Language Understanding:** If the task requires understanding nuanced language, context, or large volumes of text, LLMs can be beneficial.\n",
       "   - **Content Generation:** If you need to generate human-like text, such as writing articles, creating content, or drafting emails, LLMs are a good fit.\n",
       "\n",
       "2. **Problem Complexity:**\n",
       "   - **Pattern Recognition:** If the problem involves identifying patterns or extracting insights from text, LLMs can be effective.\n",
       "   - **Conversational AI:** LLMs are well-suited for building chatbots and virtual assistants that can handle diverse queries.\n",
       "\n",
       "3. **Data Availability:**\n",
       "   - **Training Data:** Ensure that you have sufficient and relevant data to fine-tune the LLM if needed. While pre-trained LLMs can handle many tasks out-of-the-box, specific applications may require additional training data.\n",
       "   - **Textual Data:** The quality and quantity of textual data available for training or fine-tuning will impact the performance.\n",
       "\n",
       "4. **Cost and Infrastructure:**\n",
       "   - **Resource Requirements:** Running large models can be computationally expensive and may require significant infrastructure. Evaluate if you have the resources or budget to support this.\n",
       "   - **Scalability Needs:** Consider whether the solution needs to scale and if the infrastructure can handle the scalability.\n",
       "\n",
       "5. **Accuracy and Performance:**\n",
       "   - **Precision Requirements:** If the task requires high accuracy, ensure that an LLM can meet these requirements through testing and evaluation.\n",
       "   - **Error Tolerance:** Consider how tolerant your application is to errors. LLMs can sometimes produce plausible but incorrect or nonsensical results.\n",
       "\n",
       "6. **Ethical and Compliance Considerations:**\n",
       "   - **Bias and Fairness:** Assess the risk of bias in the model's outputs and whether this is acceptable for your application.\n",
       "   - **Data Privacy:** Ensure compliance with data privacy regulations when using LLMs, especially if sensitive information is involved.\n",
       "\n",
       "7. **Integration and Implementation:**\n",
       "   - **Technical Expertise:** Determine if your team has the necessary expertise to integrate and maintain an LLM-based solution.\n",
       "   - **Compatibility with Existing Systems:** Check if the LLM solution can be integrated with your current systems and workflows.\n",
       "\n",
       "8. **Evaluation and Iteration:**\n",
       "   - **Prototype and Test:** Develop a prototype to test the LLM on your specific problem. Evaluate its performance and iterate based on the results.\n",
       "\n",
       "By considering these factors, you can assess whether an LLM is the right tool for your business problem or if another approach might be more suitable."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompts = [\n",
    "    {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "    {'role': 'user', 'content': 'How do I decide if a business problem is suitable for an LLM solution?'}\n",
    "]\n",
    "\n",
    "stream = openai.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=prompts,\n",
    "    temperature=0.7,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "reply = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "for chunk in stream:\n",
    "    reply += chunk.choices[0].delta.content or \"\"\n",
    "    reply = reply.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "    update_display(Markdown(reply), display_id=display_handle.display_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
